{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 1. Suppose we produce ten bootstrapped samples from a data set containing red and green classes. We then apply a classification tree to each bootstrapped sample and, for a specific value of X, produce 10 estimates of P(Class is Red|X): 0.1, 0.15, 0.2, 0.2, 0.55, 0.6, 0.6, 0.65, 0.7, 0.75. There are two common ways to combine these results together into a single class prediction. One is the majority vote approach. The second approach is to classify based on the average probability. In this example, what is the final classification under each of these two approaches?"
      ],
      "metadata": {
        "id": "7DrhfmCWbUnK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23rTznh48FPc",
        "outputId": "30d42737-50f7-4a9d-8d29-f9423372cb6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6 4\n",
            "For majority vote approach final classification is Red\n"
          ]
        }
      ],
      "source": [
        "estimates_p = [0.1, 0.15, 0.2, 0.2, 0.55, 0.6, 0.6, 0.65, 0.7, 0.75]\n",
        "\n",
        "# Based on the estimate values, let's take a threshold probability as '0.5'.\n",
        "threshold_p = 0.5\n",
        "\n",
        "# Approach 1 - Majority Vote\n",
        "green_count, red_count = 0, 0\n",
        "\n",
        "for i in estimates_p:\n",
        "  if i < threshold_p:\n",
        "    green_count = green_count + 1\n",
        "  else:\n",
        "    red_count = red_count + 1\n",
        "\n",
        "print(red_count, green_count)\n",
        "print('For majority vote approach final classification is','Green' if red_count < green_count else 'Red')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhSxjlME_agO",
        "outputId": "aedde1d2-6d38-4caf-a678-4d615d04cce5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Probability of class Red is 0.45\n",
            "Average Probability of class Green is 0.55\n",
            "For average probability approach final classification is Green\n"
          ]
        }
      ],
      "source": [
        "# Approach 2 - Average Probability\n",
        "import numpy as np\n",
        "mean_of_estimates_p = np.mean(estimates_p)\n",
        "print('Average Probability of class Red is',mean_of_estimates_p)\n",
        "print('Average Probability of class Green is',1 - mean_of_estimates_p)\n",
        "print('For average probability approach final classification is', 'Green' if mean_of_estimates_p < threshold_p else 'Red')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GjhdYWlDZ3Y"
      },
      "source": [
        "\n",
        "For average probability the P(Red|X) = 0.45 and P(Green|X) = 0.55 which is clearly greater than the threshold ’0.5’, hence final classification for this approach is ’Green’. Whereas in majority vote approach it’s final classification is ’Red’ because the number of estimates for class Red is 6 more when compared to class Green, 4.\n",
        "\n",
        "Both the approaches produced two different results as their final classifications. The reason over here is that computing mean is sensitive to outliers in the data. As average probability approach uses this, though the number of estimates below the threshold are ’4’, yet they are close to ’0’ rather than to the threshold value, due to this mean value is less than the threshold resulting in a different output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLf8fuweGOoQ"
      },
      "source": [
        "## Problem 2. Provide a detailed explanation of the algorithm that is used to fit a regression tree.\n",
        "\n",
        "\n",
        "Lets first look at the algorithm thats is used to fit a regression tree.\n",
        "1. We go for a top to bottom approach and use a recursive splitting on the data\n",
        "2. We do this by recursively find the best single partitioninig of the data where the reduction of residual sum of squares is highest. This will be a greedy approach.\n",
        "3. We keep in repeating the above step to each of the split parts individually until we find some minimal number of observations present in each of the leaves\n",
        "4. Cost complexity pruning is then applied to this larger tree to obtain a sequence of optimal subtrees.\n",
        "\n",
        "For each value of α there corresponds α subtree T ⊂ T0 such that \n",
        "\n",
        "$\\sum \\limits _{m=i} ^{|T|} \\sum \\limits _{i:x_{i}∈R_{m}} (y_{i}-\\hat{y}_{R_{m})^{2} + \\alpha|T|}$\n",
        "\n",
        "Here |T| represents no. of terminal nodes\n",
        "The tuning parameter α controls a trade-off between the subtree’s complexity and its fit to the training data\n",
        "\n",
        "Next we can use K-fold cross-validation to choose α\n",
        "1. For each value of K we evaluate the mean squared prediction as a function of α on the fold\n",
        "2. Average the results, and pick α to minimize the average error\n",
        "3. Taking the α selected in previous step, we return the tree calculated using the formula on the entire dataset with that chosen value of α\n",
        "\n",
        "Source: \n",
        "- https://epurdom.github.io/Stat131A/book/regression-and-classification-trees.html\n",
        "- https://daviddalpiaz.github.io/stat430fa17/slides/isl/trees.pdf (Pages 17-20)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}